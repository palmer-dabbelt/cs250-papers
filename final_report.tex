\documentclass[twocolumn]{article}
\usepackage{fullpage}
\usepackage{hyperref}

\title{CS250: An Elliptic Curve Cryptography Engine}
\author{Palmer Dabbelt and Kevin Linger}
\date{December 18, 2013}

\begin{document}
\maketitle

For our CS250 project, we implemented an elliptic curve cryptagraphy
engine that attaches via the Rocket coprocessor interface.  Our
accelerator was targeted at supporting the elliptic curve digital
signature algorithm (ECDSA), a NIST standard widely used on the
Internet for digital signatures.  We will build off previous work by
doing a more involved design-space exploration, focusing on
hardware/software co-tuning.

\section{The Swarm}

FIXME: If we need to fill space I can stick in some blurb about
swarmos here

\section{Elliptic Curve Cryptography}

Digital signature algorithms\cite{fips-186-3} are a widely used class
of algorithms that are central to the functioning of the modern
Internet.  DSA\cite{us-dsa} (the original digital signature algorithm
as standardized by NIST) is a specialization of the ElGamal signature
scheme\cite{elgamal-sig} that uses discrete logarithms over finite
integer fields.  Finite integer fields are particularly easy to
compute with electronics, so this gives DSA the advantage of being an
efficient signature algorithm.

The problem is that the discrete logarithm problem is not particularly
strong over finite integer fields (specifically, there are known
sub-exponential algorithms\cite{adleman-subexp}).  As shown in
Table~\ref{key-sizes}, DSA does not scale well to higher security
levels.  This is important because code breaking algorithms are
getting more efficient, leading to the need for higher security
levels, therefore imposing higher computational costs on every node in
the system. 

\begin{table}[h]
  \begin{center}
    \begin{tabular}{cccc}
      Security Level & DSA & ECDSA & Ratio \\
      \hline
      80 & 1024 & 160 & 3:1 \\
      112 & 2048 & 224 & 6:1 \\
      128 & 3072 & 256 & 10:1 \\
      192 & 7680 & 384 & 32:1 \\
      256 & 15360 & 521 & 64:1 \\
    \end{tabular}
  \end{center}

  \caption{Comparison of DSA and ECDSA\cite{nsa-case_for_ecc}
    \label{key-sizes}}
\end{table}

The commonly accepted solution to this problem is to change the field
from integers to elliptic curves, which (as shown in
Table~\ref{key-sizes}) scale much better to higher security levels.
While elliptic curves are significantly more difficult to build
electronics for, this will eventually be offset by sheer key size
alone.  The currently accepted security level is 128 bits, at which
ECDSA already has a 10:1 advantage in key size.  Shortening the key 
size becomes even more important, as we approach a world in which 
ubiquitous embedded systems must be able to securely transmit and 
receive data.

In addition to providing for faster cryptographic operations, this
shortened key size plays an important role specific to the swarm
related to key generation.  It is already known\cite{halderman-shared}
that we can't find sufficient entropy to generate RSA-style keys for
the machines we have, much less for a network the size of that
enviosned by the swarm project.  The main problem with generating RSA
keys is finding enough entropy to search for large prime numbers, a
problem that goes away with ECDSA because the numbers are smaller and
there's no necessity for them to be prime (there is an acceptability
criteria, but the chances of a random number not meeting it are
exceedingly low).

\section{Implementing ECDSA}

Unlike finite integer fields, elliptic curves do not map directly to
the hardware present in current microprocessors\cite{kss-ecdsa}. This
suggests that a hardware accelerator designed to compute over elliptic
curves should lead to a significantly more efficient implementation
than in software alone.  ECDSA requires more computation per bit than
DSA, so a hardware accelerator is necessary to fully take advantage of
the smaller key size.

Previous projects\cite{nnll-ecdsa_hw} have shown that ECC hardware can
be implemented efficiently, but were limited in the amount of
design-space exploration that was attempted.  \cite{mmm-hw_ecc}
explored the tradeoffs of different algorithms for computation, but
did not explore the design space of any particular algorithm, which
seems to be the extent of the design space exploration performed.  In
addition, the current state of the art appears to consist solely of
FPGA implementations.  Unfortunately these studies don't present power
numbers, which is problematic because energy is the main limiting
factor for swarm applications.

FIXME: Here's where we should describe the computational patterns of
ECDSA, use those flow charts.

\section{ASIC Implementation}

FIXME: Discuss the coprocessor interface, why it's built the way we
did (ie, no memory).  What else?

\section{Software Test Bench}

The primary goal of this project was to explore the tradeoffs involved
in adding different amounts of hardware support for ECDSA to a
pre-existing chip.  In order to achieve this, we needed to have the
ability to generate a myriad of different software configurations that
coorespond to each of the accelerator instances we generated.

The current industry standard cryptographic software, OpenSSL, is very
difficult to hack on.  Instead of messing around with OpenSSL, we
decided to instead write our own implementation of ECDSA with the
explicit goal of being paramaterizable.  We could then generate an
instance of this software that cooresponds with every accelerator
configuration that made sense and fully test our hardware.

Unfortunately, this software implementation proved to be the weakest
point of this entire project.  As shown in Figure~\ref{results}, our
code is hundreds of times slower than OpenSSL -- this is after a
significant amount of tuning, our first implementations were hundreds
of thousands of times slower than OpenSSL!  This trouble can be
attributed to two shortcommings: algorithms and tuning.

OpenSSL uses a number of significantly more complicated cryptographic
operations that our code does.  Specifically, it uses a projective
point representation that allows for the conversion of a large number
of modular multiplications into regular integer multiplications
(FIXME: is that what projective does? I forget...).  Implementing
these algorithmic improvements should show significant speedups for
both our software and hardware, so it's not entirely a bad thing.  We
estimate about a $20\times$ gain can be had from algorithmic
improvements alone!

In addition to using better algorithms, OpenSSL is implemented better
than our software was.  Specifically, OpenSSL contains hand-tuned
assembly for a number of critical paths that compilers appear to
generate bad code for (I'm specifically thinking of carry chains for
big integer operations).  Part of the problem that our implementation
had was probably related to the fact that it attempts to be
paramaterizable, which almost certainly defeats a lot of compiler
hueristics (I'd love a way to tell a compiler to generate 4 different
optimized versions of a function, sweeping arcoss the 4 different
values that one particularly interesting input can have).

Despite these shortcomings, I don't believe that the software troubles
completely invalidate the results from this project.  We spent about
the same amount of time on both the software and hardware, which
appears fair to me.  More importantly, we have numbers comparing
against the full-strength OpenSSL code running on x86 (a platform that
OpenSSL is highly optimized for\cite{kasper-openssl_ecc}).  These
numbers are probably the most reasonable to compare our ASIC
implementation against, as they're the most realistic picture of the
current state of the art.

\section{Results}

FIXME: Possibly some floorplans here?

FIXME: Some discussion of how the various numbers came to exist... :)

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{c|ccc}
      Platform        & Power & Speed  & Area \\
                      & mJ/op & op/sec & mm$^2$ \\
      \hline
      OpenSSL (45nm)  & 20    & 1000   &      \\
      x86 (45 nm)     & 4000  & 5      &      \\
      Rocket          & 800   & 0.05   &      \\
      Virtex 2 (90nm) & 4000  & 250    &      \\
      Virtex 6 (45nm) & 500   & 4000   &      \\
      \hline
      Mod Mul         & 200   & 0.3    & 0.04 \\
      Mod Mul+Div     & 2     & 20     & 0.10 \\
      Point Add+Dbl   & 0.5   & 100    & 0.31 \\
      Point Mul       & 0.06  & 400    & 0.35 \\
    \end{tabular}
  \end{center}

  \caption{Comparision of results to previous work
    \label{results}}
\end{table}

FIXME: What to say here?  Maybe a graph of those area/power numbers?

\section{Future Work}

The first order of business should probably be getting our software
implementation up to snuff -- this almost certainly means adopting
OpenSSL as our testbench, hand-tuning its assembly for RISC-V, and
then modifying it to be easily paramaterizable so it can target our
family of accelerators.

We will then have to modify our hardware implementation to take into
account the improvements that OpenSSL brings.  There are two important
algorithmic improvements that need to be made: using a projective
representation and implementing montgomery multipliers.  Both of these
have interesting time/space tradeoffs for hardware implementations, so
could serve as additional design points for our accelerator.

In addition to algorithmic improvements, there are a number of tricks
one can play to squeeze performance out of ECDSA.  The most important
one appears to be to build hand-crafted routines for operating on
particular curves -- for example, a mod routine for NIST's $p256$
curve is hundredes of times faster than a generic
one\cite{nist-routines}.

There are a number of architectural improvements that can be made to
our coprocessor interface that can help mitigate the large overhead
involved -- either placing the accelerator closer to the pipeline or
moving more state into the accelerator.  Both of these lower the
round-trip CPU to accelerator overhead and make some smaller
accelerators possible, thus providing more interesting design points.

There are also a number of interesting micro-architectural
improvements that can be made to our accelerator.  We only have a
300MHz clock, which seems exceedingly slow for what should be a
critical path of a single 256-bt adder.  Almost certainly what
happened was that there are actually two adders on the critical path,
as there are cases where one step of an algorithm requires two
additions back-to-back.  Tweaking these state machines should provide
an interesting trade-off between speed and power usage: essentially
the higher clock rate will keep more transistors toggling, they just
won't all be doing useful work.

There are also a number of benchmarking improvements that would be
interesting to see done.  Specifically, it would be good to see a
full-system benchmark running with our accelerator attached.  This
would be particularly interesting because it would allow for some
degree of parallelism to be exposed by our accelerator to the
benchmark.  This could be very interesting because we may be able to
provide light-weight accelerator contexts (compared to POSIX threads),
which could result in an interesting userspace wrapper.

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
